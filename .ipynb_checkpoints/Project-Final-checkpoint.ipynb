{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "df = pd.read_csv('kc_house_data_train.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing grade column into categorical variable\n",
    "ratings = list(df['grade'].unique())\n",
    "unrated = [4,5,6,8,9,10]\n",
    "rated = [x for x in ratings if x not in unrated]\n",
    "unrated_dict = dict.fromkeys(unrated, 'unrated')\n",
    "rated_dict  = dict(zip(rated, rated))\n",
    "ratings_map = {**rated_dict,**unrated_dict}\n",
    "df['construction_grade'] = df['grade'].map(ratings_map)\n",
    "df.replace({'construction_grade': {7: 'average', 1: 'falls short', 3: 'falls short', 11: 'high quality', 12: 'high quality', 13: 'high quality'}},inplace=True)\n",
    "\n",
    "# Changing yr_built into oldest,old,new,newest\n",
    "df['yr_built_categories'] = df['yr_built'].apply(lambda x: 'oldest' if x<1951 else('old' if 1951<=x<=1974 else('new' if 1974<=x<=1996 else \"newest\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['yr_built_categories','construction_grade','zipcode','waterfront'], drop_first=True)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "# df['date'] = df['date'].astype('str') \n",
    "# df[\"date\"]= df[\"date\"].str.split(\"T\", n = 1, expand = True) \n",
    "df['yr_old'] =  df['yr_built'].map(lambda x: 2020-x )\n",
    "features = ['bedrooms', 'bathrooms', 'sqft_living',\n",
    "       'sqft_lot', 'floors', 'view', 'condition', 'sqft_above',\n",
    "       'sqft_basement', 'yr_built', 'yr_renovated', 'lat', 'long',\n",
    "       'sqft_living15', 'sqft_lot15',\n",
    "       'construction_grade_falls short', 'construction_grade_high quality',\n",
    "       'construction_grade_unrated', 'waterfront_1',\n",
    "        'zipcode_98002', 'zipcode_98003', 'zipcode_98004',\n",
    "       'zipcode_98005', 'zipcode_98006', 'zipcode_98007', 'zipcode_98008',\n",
    "       'zipcode_98010', 'zipcode_98011', 'zipcode_98014', 'zipcode_98019',\n",
    "       'zipcode_98022', 'zipcode_98023', 'zipcode_98024', 'zipcode_98027',\n",
    "       'zipcode_98028', 'zipcode_98029', 'zipcode_98030', 'zipcode_98031',\n",
    "       'zipcode_98032', 'zipcode_98033', 'zipcode_98034', 'zipcode_98038',\n",
    "       'zipcode_98039', 'zipcode_98040', 'zipcode_98042', 'zipcode_98045',\n",
    "       'zipcode_98052', 'zipcode_98053', 'zipcode_98055', 'zipcode_98056',\n",
    "       'zipcode_98058', 'zipcode_98059', 'zipcode_98065', 'zipcode_98070',\n",
    "       'zipcode_98072', 'zipcode_98074', 'zipcode_98075', 'zipcode_98077',\n",
    "       'zipcode_98092', 'zipcode_98102', 'zipcode_98103', 'zipcode_98105',\n",
    "       'zipcode_98106', 'zipcode_98107', 'zipcode_98108', 'zipcode_98109',\n",
    "       'zipcode_98112', 'zipcode_98115', 'zipcode_98116', 'zipcode_98117',\n",
    "       'zipcode_98118', 'zipcode_98119', 'zipcode_98122', 'zipcode_98125',\n",
    "       'zipcode_98126', 'zipcode_98133', 'zipcode_98136', 'zipcode_98144',\n",
    "       'zipcode_98146', 'zipcode_98148', 'zipcode_98155', 'zipcode_98166',\n",
    "       'zipcode_98168', 'zipcode_98177', 'zipcode_98178', 'zipcode_98188',\n",
    "       'zipcode_98198', 'zipcode_98199', 'yr_old','yr_built_categories_newest',\n",
    "       'yr_built_categories_old', 'yr_built_categories_oldest']\n",
    "df_features = df[features]\n",
    "target = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bedrooms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sqft_lot.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqftlot_90p = df.sqft_lot.quantile(0.90)\n",
    "sqftlot_90p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sqft_lot = df.sqft_lot.where(df['sqft_lot'] != df['sqft_lot'].max(), sqftlot_90p) \n",
    "df.sqft_lot.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bedrooms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrooms_90p = df.bedrooms.quantile(0.90)\n",
    "bedrooms_90p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bedrooms = df.bedrooms.where(df['bedrooms'] != df['bedrooms'].max(), bedrooms_90p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bedrooms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_features, target, random_state=35,test_size=0.2)\n",
    "print(\"Training set - Features: \", X_train.shape, \"Target: \", y_train.shape)\n",
    "print(\"Training set - Features: \", X_test.shape, \"Target: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have my training and testing datasets, I am going to apply my feature scaler to the dataset.  \n",
    "\n",
    "**Why amy I sacling my data after the train-test split and not before?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "#transform the training data\n",
    "X_train = pd.DataFrame(data=scaler.transform(X_train), columns=df_features.columns)\n",
    "\n",
    "#transform the testing dat\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test), columns=df_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm = lm.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lm.predict(X_train)\n",
    "\n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , train_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use fitted model to predict on the test examples\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "#evaluate the predictions on the test examples\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , test_rmse)\n",
    "\n",
    "\n",
    "print('Training: ', int(train_rmse), \"vs. Testing: \", int(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Plot the residuals after fitting a linear model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot( y_train, y_train_pred,lowess=True, color=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot( y_test, y_pred, lowess=True, color=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take the square root of the target data to determine if this model is more accurate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the natural log of the target variable\n",
    "y_log = np.log(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm_log = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_log = lm_log.fit(X_train, y_log)\n",
    "\n",
    "y_train_pred = lm_log.predict(X_train)\n",
    "\n",
    "#exponentiate the predictions to get them on the same original scale \n",
    "y_train_pred = np.exp(y_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , train_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the new model to predict the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lm_log.predict(X_test)\n",
    "\n",
    "\n",
    "#our model predcicte the log of gross, so now we must exponentiate to get the value in $\n",
    "y_test_pred = np.exp(y_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , test_rmse)\n",
    "\n",
    "\n",
    "print('Training: ', int(train_rmse), \"vs. Testing: \", int(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot( y_test, y_test_pred, lowess=True, color=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Polynomial and Interaction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_2 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly2_data = poly_2.fit_transform(df_features)\n",
    "poly2_columns = poly_2.get_feature_names(df_features.columns)\n",
    "df_poly2 = pd.DataFrame(poly2_data, columns=poly2_columns)\n",
    "df_poly2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poly2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_poly2, target, random_state=33,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = StandardScaler()\n",
    "# fit the scaler to the training data\n",
    "scaler2.fit(X_train)\n",
    "\n",
    "#transform the training data\n",
    "X_train = pd.DataFrame(data=scaler2.transform(X_train), columns=df_poly2.columns)\n",
    "\n",
    "#transform the testing dat\n",
    "X_test = pd.DataFrame(data=scaler2.transform(X_test), columns=df_poly2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a linear regression object\n",
    "lm_2 = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_2 = lm_2.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lm_2.predict(X_train)\n",
    "\n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "print(\"R^2: \", lm_2.score(df_poly2, target))\n",
    "print('Training Root Mean Squared Error:' , train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use fitted model to predict on test data\n",
    "y_pred = lm_2.predict(X_test)\n",
    "\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , test_rmse)\n",
    "\n",
    "\n",
    "print('Training: ', int(train_rmse), \"vs. Testing: \", int(test_rmse))\n",
    "# TRAINING ERROR SHOULD BE LOWER THAN TESTING ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Methods\n",
    "Filter feature selection methods apply a statistical measure to assign a scoring to each feature. The features are ranked by the score and either selected to be kept or removed from the dataset. The methods are often univariate and consider the feature independently, or with regard to the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = X_train.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find index of feature columns with correlation greater than 0.90\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
    "\n",
    "#if you change inplace to True it will go through and drop all of those columns from the dataset\n",
    "X_train.drop(columns=to_drop, inplace=False)\n",
    "X_test.drop(columns=to_drop, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Inflation Factor (VIF) \n",
    "\n",
    "VIFis a measure of colinearity among predictor variables within a multiple regression. The variance inflation factor for the estimated regression coefficient $b_j$ — denoted $VIF_j$ —is just the factor by which the variance of $b_j$ is \"inflated\" by the existence of correlation among the predictor variables in the model.In particular, the variance inflation factor for the jth predictor is:\n",
    "\n",
    "$$VIF_j=\\frac{1}{1-R_{j}^{2}}$$\n",
    "\n",
    "\n",
    "where $R^2_j$  is the $R^2$-value obtained by regressing the jth predictor on the remaining predictors. \n",
    "\n",
    "\n",
    "Inspect the factors for each predictor variable, if the VIF is between 5-10, multicolinearity is likely present and you should consider dropping the variable.\n",
    "\n",
    "https://online.stat.psu.edu/stat462/node/180/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(df_features.values, i) for i in range(df_features.shape[1])]\n",
    "vif[\"features\"] = df_features.columns\n",
    "vif.round(1)\n",
    "# DO THIS BEFORE POLYNOMIAL AND INTERACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.corrwith(target).abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  F Test\n",
    "\n",
    "F Test is a statistical test used to compare between models and check if the difference is significant between the model.\n",
    "\n",
    "F-Test does a hypothesis testing model X and Y where X is a model created by just a constant and Y is the model created by a constant and a feature.\n",
    "\n",
    "The least square errors in both the models are compared and checks if the difference in errors between model X and Y are significant or introduced by chance.\n",
    "\n",
    "F-Test is useful in feature selection as we get to know the significance of each feature in improving the model.\n",
    "\n",
    "Scikit learn provides the Selecting K best features using F-Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "\n",
    "selector = SelectKBest(f_regression, k=15)\n",
    "#run regression on x train and y train and return top 15 features\n",
    "selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = X_train.columns[selector.get_support()]\n",
    "removed_columns = X_train.columns[~selector.get_support()]\n",
    "# X_train = X_train[selected_columns]\n",
    "# X_test = X_test[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(removed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm_kbest = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_kbest = lm_kbest.fit(X_train[selected_columns], y_train)\n",
    "\n",
    "y_train_kbest = lm_kbest.predict(X_train[selected_columns])\n",
    "\n",
    "\n",
    "trainK_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_kbest))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , trainK_rmse)\n",
    "\n",
    "y_kbest = lm_kbest.predict(X_test[selected_columns])\n",
    "\n",
    "testK_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_kbest))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , testK_rmse)\n",
    "\n",
    "\n",
    "print('Original: ', test_rmse, \"vs. KBest: \", testK_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper Methods\n",
    "\n",
    "Wrapper methods consider the selection of a set of features as a search problem, where different combinations are prepared, evaluated and compared to other combinations. A predictive model is used to evaluate a combination of features and assign a score based on model accuracy.\n",
    "\n",
    "The search process may be methodical such as a best-first search, it may stochastic such as a random hill-climbing algorithm, or it may use heuristics, like forward and backward passes to add and remove features.\n",
    "\n",
    "Wrapper Methods promises you a best set of features with a extensive greedy search.\n",
    "\n",
    "But the main drawbacks of wrapper methods is the sheer amount of models that needs to be trained. It is computationally very expensive and is infeasible with large number of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create recursive feature eliminator that scores features by mean squared errors\n",
    "selector = RFECV(estimator=ols, step=1, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit recursive feature eliminator \n",
    "selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rfe = X_train.columns[selector.support_]\n",
    "removed_rfe = X_train.columns[~selector.support_]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(removed_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(selected_rfe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm_rfe = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_rfe = lm_rfe.fit(X_train[selected_rfe], y_train)\n",
    "\n",
    "y_rfe = lm_rfe.predict(X_train[selected_rfe])\n",
    "\n",
    "\n",
    "trainRFE_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_rfe))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , trainRFE_rmse)\n",
    "\n",
    "y_pred_rfe = lm_rfe.predict(X_test[selected_rfe])\n",
    "\n",
    "testRFE_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred_rfe))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , testRFE_rmse)\n",
    "\n",
    "\n",
    "print('Original: ', test_rmse, \"vs. KBest: \", testK_rmse, \"vs. RFE: \", testRFE_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedded Methods\n",
    "\n",
    "Embedded methods learn which features best contribute to the accuracy of the model while the model is being created. The most common type of embedded feature selection methods are regularization methods.\n",
    "\n",
    "Regularization methods are also called penalization methods that introduce additional constraints into the optimization of a predictive algorithm (such as a regression algorithm) that bias the model toward lower complexity (fewer coefficients).\n",
    "\n",
    "Examples of regularization algorithms are the LASSO, Elastic Net and Ridge Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.DataFrame(data=lm_rfe.coef_ ).T\n",
    "coef.columns = selected_rfe\n",
    "\n",
    "model_coef = coef.T.sort_values(by=0).T\n",
    "model_coef.plot(kind='bar', title='Modal Coefficients', legend=False, figsize=(16,8),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training the model\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.01, normalize=False)\n",
    "\n",
    "lasso.fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = lasso.predict(X_train)\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "train_rmse = metrics.mean_absolute_error(y_train, y_train_pred)\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Training Error: '+ str(train_rmse) )\n",
    "print('Testing Error: '+ str(test_rmse) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef01 = pd.DataFrame(data=lasso.coef_).T\n",
    "lasso_coef01.columns = X_train.columns\n",
    "lasso_coef01 = lasso_coef01.T.sort_values(by=0).T\n",
    "lasso_coef01.plot(kind='bar', title='Modal Coefficients', legend=False, figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef01.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training the model\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso1 = Lasso(alpha=.1, normalize=False)\n",
    "\n",
    "lasso1.fit(X_train,y_train)\n",
    "\n",
    "y_train_lasso1 = lasso1.predict(X_train)\n",
    "y_pred_lasso1 = lasso1.predict(X_test)\n",
    "\n",
    "train_rmse_lasso1 = metrics.mean_absolute_error(y_train, y_train_lasso1)\n",
    "test_rmse_lasso1 = np.sqrt(metrics.mean_squared_error(y_test, y_pred_lasso1))\n",
    "print('Training Error: '+ str(train_rmse_lasso1) )\n",
    "print('Testing Error: '+ str(test_rmse_lasso1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef1 = pd.DataFrame(data=lasso1.coef_).T\n",
    "lasso_coef1.columns = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lasso_coef1 = lasso_coef1.T.sort_values(by=0).T\n",
    "lasso_coef1.plot(kind='bar', title='Modal Coefficients', legend=False, figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
